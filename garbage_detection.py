# ì‹¤í–‰ ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”
# pip install ultralytics opencv-python torch torchvision requests

# ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰
# source venv/bin/activate && python garbage_detection.py

import base64
import time
from collections import defaultdict, deque
from datetime import datetime

import cv2
import requests
import torch
from ultralytics import YOLO


class GarbageDetector:
    def __init__(self, model_path='yolo11m.pt', server_url="http://localhost:8000"):

        self.model = YOLO(model_path)
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1440)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        self.cap.set(cv2.CAP_PROP_FPS, 30)  # ë†’ì€ í”„ë ˆì„ ë ˆì´íŠ¸ ì„¤ì •
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™”ë¡œ ì§€ì—° ê°ì†Œ

        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"Using device: {self.device}")

        # ì„œë²„ ì—°ê²° ì„¤ì •
        self.server_url = server_url
        self.server_connected = False
        self.test_server_connection()

        # ê°ì§€ í†µê³„
        self.detection_stats = {
            'total_detections': 0,
            'last_detection_time': None,
            'current_risk_score': 0,
            'current_risk_level': 'safe'
        }

        self.taco_classes = {
            0: 'Aluminium foil',
            1: 'Battery',
            2: 'Aluminium blister pack',
            3: 'Carded blister pack',
            4: 'Other plastic bottle',
            5: 'Clear plastic bottle',
            6: 'Glass bottle',
            7: 'Plastic bottle cap',
            8: 'Metal bottle cap',
            9: 'Broken glass',
            10: 'Food Can',
            11: 'Aerosol',
            12: 'Drink can',
            13: 'Toilet tube',
            14: 'Other carton',
            15: 'Egg carton',
            16: 'Drink carton',
            17: 'Corrugated carton',
            18: 'Meal carton',
            19: 'Pizza box',
            20: 'Paper cup',
            21: 'Disposable plastic cup',
            22: 'Foam cup',
            23: 'Glass cup',
            24: 'Other plastic cup',
            25: 'Food waste',
            26: 'Glass jar',
            27: 'Plastic lid',
            28: 'Metal lid',
            29: 'Other plastic',
            30: 'Magazine paper',
            31: 'Tissues',
            32: 'Wrapping paper',
            33: 'Normal paper',
            34: 'Paper bag',
            35: 'Plastified paper bag',
            36: 'Plastic film',
            37: 'Six pack rings',
            38: 'Garbage bag',
            39: 'Other plastic wrapper',
            40: 'Single-use carrier bag',
            41: 'Polypropylene bag',
            42: 'Crisp packet',
            43: 'Spread tub',
            44: 'Tupperware',
            45: 'Disposable food container',
            46: 'Foam food container',
            47: 'Other plastic container',
            48: 'Plastic glooves',
            49: 'Plastic utensils',
            50: 'Pop tab',
            51: 'Rope & strings',
            52: 'Scrap metal',
            53: 'Shoe',
            54: 'Squeezable tube',
            55: 'Plastic straw',
            56: 'Paper straw',
            57: 'Styrofoam piece',
            58: 'Unlabeled litter',
            59: 'Cigarette'
        }

        self.category_mapping = {
            'plastic': [4, 5, 7, 21, 24, 27, 29, 36, 37, 39, 40, 41, 44, 47, 48, 49, 55],  # í”Œë¼ìŠ¤í‹±ë¥˜
            'metal': [0, 8, 10, 11, 12, 28, 50, 52],  # ê¸ˆì†ë¥˜
            'glass': [6, 9, 23, 26],  # ìœ ë¦¬ë¥˜
            'paper': [13, 14, 15, 16, 17, 18, 19, 20, 30, 31, 32, 33, 34, 35, 56],  # ì¢…ì´ë¥˜
            'food_container': [22, 25, 42, 43, 45, 46, 53, 54, 57],  # ì‹í’ˆìš©ê¸°ë¥˜
            'other': [1, 2, 3, 38, 51, 58, 59]  # ê¸°íƒ€
        }

        self.confidence_threshold = 0.1  # ë‚®ì€ ì‹ ë¢°ë„ë¡œ ë” ë§ì€ ê°ì²´ ê°ì§€
        self.detection_history = defaultdict(lambda: deque(maxlen=30))  # 1ì´ˆ * 30fps = 30í”„ë ˆì„ìœ¼ë¡œ ë‹¨ì¶•
        self.stable_detections = {}
        self.min_detection_frames = 1  # 1í”„ë ˆì„ë§Œìœ¼ë¡œë„ ì¦‰ì‹œ ê°ì§€
        self.max_missing_frames = 3  # ë¹ ë¥¸ ê°ì²´ ì œê±°ë¡œ ê²¹ì¹¨ ë°©ì§€
        self.frame_skip = 0
        self.process_every_n_frames = 1  # ë§¤ í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ë¡œ ë” ë¹ ë¥¸ ì¸ì‹
        self.last_stable_detections = []
        
        # ê²¹ì³ì§„ ê°ì²´ ê°ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        self.overlap_threshold = 0.3  # ë” ë‚®ì€ ê²¹ì¹¨ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ ê°ì²´ í—ˆìš©
        self.multi_scale_detection = True

        self.category_colors = {
            'plastic': (0, 165, 255),
            'metal': (0, 255, 255),
            'glass': (255, 0, 255),
            'paper': (0, 255, 0),
            'food_container': (255, 0, 0),
            'other': (128, 128, 128)
        }

    def test_server_connection(self):
        """FastAPI ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.server_url}/health", timeout=3)
            if response.status_code == 200:
                self.server_connected = True
                print(f"âœ… ì„œë²„ ì—°ê²° ì„±ê³µ: {self.server_url}")
                print(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ: {self.server_url}")
            else:
                print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                self.server_connected = False
        except Exception as e:
            print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            print(f"ğŸ’¡ ì„œë²„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: python backend/app.py")
            self.server_connected = False

    def send_detection_to_server(self, detection_data):
        """ê°ì§€ ë°ì´í„°ë¥¼ FastAPI ì„œë²„ë¡œ ì „ì†¡"""
        if not self.server_connected:
            return False

        try:
            response = requests.post(
                f"{self.server_url}/detect",
                json=detection_data,
                timeout=1  # ë” ë¹ ë¥¸ ì‘ë‹µ
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('significant_change', False):
                    print(f"ğŸš¨ ìœ„í—˜ë„ ë³€í™”: {result.get('risk_score', 0):.1f}% ({result.get('risk_level', 'safe')})")
                elif result.get('duplicate', False):
                    print(f"ğŸ”„ ì¤‘ë³µ ê°ì§€ ë¬´ì‹œ")
                return result
            else:
                print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False

        except requests.exceptions.Timeout:
            print("â° ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
            return False
        except Exception as e:
            print(f"âŒ ì„œë²„ ì „ì†¡ ì˜¤ë¥˜: {e}")
            self.test_server_connection()
            return False

    def send_frame_to_server(self, frame):
        """í˜„ì¬ í”„ë ˆì„ì„ ì„œë²„ë¡œ ì „ì†¡ (ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ìš©)"""
        if not self.server_connected:
            return False

        try:
            # í”„ë ˆì„ í¬ê¸° ì¶•ì†Œë¡œ ì „ì†¡ ì†ë„ í–¥ìƒ
            resized_frame = cv2.resize(frame, (320, 240))
            ret, buffer = cv2.imencode('.jpg', resized_frame, [cv2.IMWRITE_JPEG_QUALITY, 75])  # í’ˆì§ˆ í–¥ìƒí•˜ë˜ í¬ê¸° ì¶•ì†Œ
            if not ret:
                return False

            frame_base64 = base64.b64encode(buffer).decode('utf-8')

            response = requests.post(
                f"{self.server_url}/update_frame",
                json={"frame": frame_base64},
                timeout=0.05  # ë” ì§§ì€ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ
            )

            return response.status_code == 200

        except:
            return False

    def update_tracking(self, current_detections):
        for detection in current_detections:
            if len(detection) == 7:
                box, confidence, class_id, class_name, label, category, color = detection
            else:
                box, confidence, class_id, class_name, label = detection
            best_match_id = None

            for track_id, track_info in list(self.stable_detections.items())[:10]:
                if track_info['class_id'] == class_id:
                    center1 = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)
                    center2 = ((track_info['box'][0] + track_info['box'][2]) / 2,
                               (track_info['box'][1] + track_info['box'][3]) / 2)
                    distance = ((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2) ** 0.5

                    if distance < 100:
                        best_match_id = track_id
                        break

            if best_match_id:
                detection_data = {'box': box, 'confidence': confidence, 'missing_frames': 0}
                if len(detection) >= 7:
                    detection_data.update({'category': detection[5], 'color': detection[6]})
                self.stable_detections[best_match_id].update(detection_data)
                self.detection_history[best_match_id].append(True)
            else:
                new_id = len(self.stable_detections)
                detection_data = {
                    'box': box, 'confidence': confidence, 'class_id': class_id,
                    'class_name': class_name, 'label': label, 'missing_frames': 0
                }
                if len(detection) >= 7:
                    detection_data.update({'category': detection[5], 'color': detection[6]})

                self.stable_detections[new_id] = detection_data
                self.detection_history[new_id].append(True)

        to_remove = [track_id for track_id, track_info in self.stable_detections.items()
                     if track_info['missing_frames'] > self.max_missing_frames]

        for track_id in to_remove:
            del self.stable_detections[track_id]
            del self.detection_history[track_id]

        for track_id in self.stable_detections:
            if track_id not in [idx for idx, _ in enumerate(current_detections)]:
                self.stable_detections[track_id]['missing_frames'] += 1
                self.detection_history[track_id].append(False)

        stable_results = []
        for track_id, track_info in self.stable_detections.items():
            if sum(self.detection_history[track_id]) >= self.min_detection_frames:
                result = (track_info['box'], track_info['confidence'], track_info['class_id'],
                          track_info['class_name'], track_info['label'])
                if 'category' in track_info and 'color' in track_info:
                    result = result + (track_info['category'], track_info['color'])
                stable_results.append(result)

                # ê°ì§€ê°€ ì²˜ìŒ í™•ì •ë  ë•Œë§ˆë‹¤ ì„œë²„ë¡œ ì „ì†¡
                if sum(self.detection_history[track_id]) == self.min_detection_frames:
                    box = track_info['box']
                    area = (box[2] - box[0]) * (box[3] - box[1])

                    if 'category' in track_info:
                        garbage_type = f"{track_info['category']}_{track_info['class_name']}"
                    else:
                        garbage_type = f"other_{track_info['class_name']}"

                    detection_data = {
                        "timestamp": datetime.now().isoformat(),
                        "garbage_type": garbage_type,
                        "confidence": float(track_info['confidence']),
                        "bbox": [int(box[0]), int(box[1]), int(box[2]), int(box[3])],
                        "area": float(area),
                        "location": "main_pipe"
                    }

                    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„œë²„ë¡œ ì „ì†¡ (ë©”ì¸ ë£¨í”„ì— ì˜í–¥ ì—†ë„ë¡)
                    import threading
                    def send_async():
                        result = self.send_detection_to_server(detection_data)
                        if result:
                            print(f"ğŸ“¤ ê°ì§€ ì „ì†¡: {garbage_type} (ì‹ ë¢°ë„: {detection_data['confidence']:.2f})")
                            # í†µê³„ ì—…ë°ì´íŠ¸
                            self.detection_stats['total_detections'] += 1
                            self.detection_stats['last_detection_time'] = datetime.now()
                            if isinstance(result, dict):
                                self.detection_stats['current_risk_score'] = result.get('risk_score', 0)
                                self.detection_stats['current_risk_level'] = result.get('risk_level', 'safe')
                                print(
                                    f"ğŸ“Š ìœ„í—˜ë„ ì—…ë°ì´íŠ¸: {result.get('risk_score', 0):.1f}% ({result.get('risk_level', 'safe')})")
                        else:
                            print(f"âŒ ì„œë²„ ì‘ë‹µ ì—†ìŒ: {garbage_type}")

                    thread = threading.Thread(target=send_async)
                    thread.daemon = True
                    thread.start()

        return stable_results

    def get_category_for_class(self, class_id):
        for category, class_ids in self.category_mapping.items():
            if class_id in class_ids:
                return category
        return 'other'

    def get_class_info(self, class_id):
        class_name = self.taco_classes.get(class_id, f'Unknown_{class_id}')
        category = self.get_category_for_class(class_id)
        color = self.category_colors.get(category, (128, 128, 128))
        return class_name, category, color

    def detect_garbage(self, frame):
        # ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ ìœ¼ë¡œ ê²¹ì³ì§„ ê°ì²´ ì¸ì‹ í–¥ìƒ
        enhanced_frame = cv2.convertScaleAbs(frame, alpha=1.1, beta=10)  # ëŒ€ë¹„ì™€ ë°ê¸° í–¥ìƒ
        
        # ê²¹ì³ì§„ ì“°ë ˆê¸° ì „ì²´ ì¸ì‹ì„ ìœ„í•œ ì„¤ì •
        # ë©€í‹°ìŠ¤ì¼€ì¼ ê°ì§€: ë‹¤ì–‘í•œ í¬ê¸°ë¡œ ê°ì§€ ì‹œë„
        results = self.model(enhanced_frame, device=self.device, conf=0.1, iou=0.2, verbose=False, 
                           agnostic_nms=True, max_det=100, augment=True)

        self.frame_skip += 1
        if self.frame_skip % self.process_every_n_frames != 0:
            if hasattr(self, 'last_stable_detections'):
                stable_detections = self.last_stable_detections
            else:
                stable_detections = []
        else:
            current_detections = []

            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        class_name = self.model.names[class_id]

                        if class_id in self.taco_classes and class_id != 0:  # ì•Œë£¨ë¯¸ëŠ„ í˜¸ì¼(0ë²ˆ) ì œì™¸
                            class_name, category, color = self.get_class_info(class_id)
                            label = f"{category.upper()}: {class_name} ({confidence:.2f})"
                            current_detections.append(
                                ([x1, y1, x2, y2], confidence, class_id, class_name, label, category, color))
                        else:
                            model_class_name = self.model.names.get(class_id, f'Unknown_{class_id}')
                            # ì‚¬ëŒ(person) í´ë˜ìŠ¤ ì œì™¸
                            if model_class_name.lower() != 'person':
                                label = f"OTHER: {model_class_name} ({confidence:.2f})"
                                current_detections.append(
                                    ([x1, y1, x2, y2], confidence, class_id, model_class_name, label, 'other',
                                     (128, 128, 128)))

            stable_detections = self.update_tracking(current_detections)
            self.last_stable_detections = stable_detections

        return self._draw_detections(frame, stable_detections)

    def _draw_detections(self, frame, detections):
        annotated_frame = frame.copy()

        for detection in detections:
            if len(detection) == 7:
                box, confidence, class_id, class_name, label, category, box_color = detection
            else:
                box, confidence, class_id, class_name, label = detection
                box_color = (0, 0, 255)

            x1, y1, x2, y2 = box
            # ë°•ìŠ¤ë§Œ ê·¸ë¦¬ê³  í…ìŠ¤íŠ¸ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), box_color, 2)

        return annotated_frame

    def run(self):
        print("ì“°ë ˆê¸° íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ESC í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        print(f"ëª¨ë¸: {self.model.ckpt_path}")
        print("ğŸ“‹ ì‚¬ìš©ë²•:")
        print("   - ESC: í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        print("   - R: ì„œë²„ ì¬ì—°ê²°")
        print("   - S: ì„œë²„ ìƒíƒœ í™•ì¸")

        frame_count = 0
        last_status_check = time.time()

        while True:
            ret, frame = self.cap.read()
            if not ret:
                print("ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            annotated_frame = self.detect_garbage(frame)

            # ì„œë²„ë¡œ í˜„ì¬ í”„ë ˆì„ ì „ì†¡ (ì›¹ ëŒ€ì‹œë³´ë“œìš©) - ì„±ëŠ¥ ìµœì í™”
            if frame_count % 5 == 0 and self.server_connected:  # 5í”„ë ˆì„ë§ˆë‹¤ ì „ì†¡ìœ¼ë¡œ ë”œë ˆì´ ê°ì†Œ
                import threading
                try:
                    # ì“°ë ˆë“œ í’€ ëŒ€ì‹  ê°„ë‹¨í•œ ë¹„ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
                    def send_frame_async():
                        self.send_frame_to_server(annotated_frame)

                    thread = threading.Thread(target=send_frame_async)
                    thread.daemon = True
                    thread.start()
                except:
                    pass  # ì“°ë ˆë“œ ìƒì„± ì‹¤íŒ¨ì‹œ ë¬´ì‹œ

            # ì£¼ê¸°ì  ì„œë²„ ìƒíƒœ í™•ì¸
            if time.time() - last_status_check > 30:  # 30ì´ˆë§ˆë‹¤
                self.test_server_connection()
                last_status_check = time.time()

            # ìƒíƒœ ì •ë³´ í‘œì‹œ
            status_color = (0, 255, 0) if self.server_connected else (0, 0, 255)
            status_text = f"Server: {'Connected' if self.server_connected else 'Disconnected'}"
            cv2.putText(annotated_frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
            cv2.putText(annotated_frame, f"Detections: {self.detection_stats['total_detections']}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(annotated_frame,
                        f"Risk: {self.detection_stats['current_risk_score']:.1f}% ({self.detection_stats['current_risk_level']})",
                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(annotated_frame, "Press ESC to exit", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),
                        2)

            cv2.imshow('Garbage Detection', annotated_frame)

            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC í‚¤
                break
            elif key == ord('r') or key == ord('R'):  # R í‚¤
                print("ğŸ”„ ì„œë²„ ì¬ì—°ê²° ì‹œë„...")
                self.test_server_connection()
            elif key == ord('s') or key == ord('S'):  # S í‚¤
                print("ğŸ“Š ì„œë²„ ìƒíƒœ í™•ì¸...")
                self.test_server_connection()

            frame_count += 1

        self.cap.release()
        cv2.destroyAllWindows()
        print("í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    print("ğŸš° í•˜ìˆ˜ë„ ë§‰í˜ ê°ì§€ AI ì‹œìŠ¤í…œ")
    print("=" * 50)

    # ëª¨ë¸ ì„ íƒ (ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ë³€ê²½)
    model_path = 'yolo11m.pt'  # ê°€ë²¼ìš´ nano ëª¨ë¸

    # ì»¤ìŠ¤í…€ ëª¨ë¸ì´ ìˆë‹¤ë©´ ì‚¬ìš©
    import os
    if os.path.exists('best.pt'):
        model_path = 'best.pt'
        print("ğŸ¯ ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: best.pt")
    else:
        print("ğŸ”§ ê¸°ë³¸ YOLO ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: yolo11m.pt")

    # ê°ì§€ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    detector = GarbageDetector(model_path)
    detector.run()


if __name__ == "__main__":
    main()